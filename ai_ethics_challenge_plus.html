<!DOCTYPE html>
<html lang="ro">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>AI Ethics Challenge</title>
<style>
  :root{--bg:#0b0e14;--card:#101421;--muted:#aeb6c6;--accent:#7aa2ff;--good:#31d0aa;--warn:#ffbe55;--bad:#ff6b6b}
  *{box-sizing:border-box}
  html,body{margin:0;background:var(--bg);color:#e9edf6;font-family:system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Cantarell,Noto Sans,sans-serif}
  .wrap{max-width:1000px;margin:0 auto;padding:28px 18px 90px}
  h1{margin:0 0 10px 0;font-size:clamp(24px,3.2vw,36px)}
  p.lead{margin:.25rem 0 1rem;color:var(--muted)}
  .card{background:var(--card);border:1px solid #1b2338;border-radius:16px;padding:20px;margin:16px 0;box-shadow:0 6px 20px rgba(0,0,0,.25)}
  .choices{display:grid;gap:10px;margin-top:12px}
  .choice{padding:12px 14px;border:1px solid #1b2338;border-radius:12px;background:#0f1324;cursor:pointer;transition:transform .05s ease}
  .choice:hover{transform:translateY(-1px);border-color:#283456}
  .choice.good{border-color:var(--good)}
  .choice.warn{border-color:var(--warn)}
  .choice.bad{border-color:var(--bad)}
  .feedback{margin-top:12px;padding:12px 14px;border-radius:12px;background:#0f1426;border:1px dashed #2a3553}
  .feedback.good{border-color:var(--good);color:#d9fff4}
  .feedback.warn{border-color:var(--warn);color:#fff0d6}
  .feedback.bad{border-color:var(--bad);color:#ffe5e5}
  .bar{height:10px;background:#1d2742;border-radius:999px;overflow:hidden;margin:8px 0 2px}
  .bar > span{display:block;height:100%;background:linear-gradient(90deg,var(--accent),#9ac2ff);width:0%}
  .small{color:var(--muted);font-size:.92rem}
  .footer{display:flex;justify-content:space-between;align-items:center;gap:10px;margin-top:14px}
  button{border:0;background:var(--accent);color:#0b0e14;font-weight:700;padding:12px 16px;border-radius:12px;cursor:pointer}
  button.secondary{background:#232b46;color:#dbe6ff}
  .end h2{margin:.2rem 0}
  .grid{display:grid;gap:10px}
  .persona{display:flex;gap:12px;align-items:flex-start}
  .badge{font-size:28px}
  ul{margin:.3rem 0 0 1.2rem}
  .tip{background:#0e162b;border:1px solid #243158;padding:10px 12px;border-radius:12px}
  .two{display:grid;grid-template-columns:1fr 1fr;gap:16px}
  @media (max-width: 760px){ .two{grid-template-columns:1fr} }
</style>
</head>
<body>
<div class="wrap">
  <h1>AI Ethics Challenge <span style="font-size:.7em;opacity:.7"></span></h1>
  <p class="lead">Intră în jocul celor 8 scenarii de etică AI. În fiecare pas vei lua decizii, vei primi feedback instant și, la final, vei afla care este profilul tău etic, însoțit de sfaturi pentru a merge mai departe.</p>

  <div class="card">
    <div class="small">Progres</div>
    <div class="bar"><span id="prog"></span></div>
    <div class="small"><span id="stepTxt">Scenariul 1/8</span> • Scor: <b id="scoreTxt">0</b></div>
  </div>

  <div id="game" class="card grid"></div>
  <div id="end" class="card end" style="display:none"></div>

  <div class="card tip">
    <div class="small">Criterii cheie analizate:</div>
    Scopul jocului nu e doar să alegi rapid, ci să vezi cât de mult respecți principiile esențiale ale eticii AI. Deciziile tale vor fi analizate prin prisma unor principii esențiale pentru utilizarea responsabilă a inteligenței artificiale: nediscriminare și auditarea biasului; transparență și explicabilitate; consimțământ și respectarea legii; minimizarea datelor; proporționalitate; siguranță și evaluarea riscurilor; integritatea informației (de ex. deepfakes, halucinații).
  </div>
</div>

<script>
// Scoruri: good +3, better +2, safe-but-limiting +1, warn -1, bad -2/-3
const scenarios = [
  {
    title: "Admitere universitară automatizată",
    text: `Universitatea se confruntă cu un număr tot mai mare de aplicații pentru programele sale și decide să implementeze un model AI care să trieze candidații în faza inițială. Modelul se bazează pe date istorice din ultimii 10 ani, care includ informații despre performanța academică a studenților, recomandări, activități extracurriculare și date demografice. Problema este că aceste date istorice reflectă deja anumite inechități: candidații din medii defavorizate au fost adesea subreprezentați, iar recomandările profesorilor au putut fi influențate de prejudecăți. Există riscul ca AI-ul să perpetueze sau chiar să amplifice aceste biasuri.
    
    Universitatea trebuie să decidă cum să folosească AI-ul: va merge pe varianta rapidă, lăsând algoritmul să facă selecția automat, va combina AI-ul cu verificări umane și audit de bias, sau va renunța complet la AI pentru a evita orice risc?`,
    
    choices: [
      {label:"Rulezi AI imediat pentru eficiență", score:-2, tone:"bad",
       fb:`Această decizie maximizează viteza și reduce costurile, dar compromite echitatea. Modelul va reflecta și întări prejudecățile din datele istorice, ceea ce poate duce la excluderea sistematică a unor grupuri de candidați. În plus, universitatea riscă plângeri legale și reputaționale pentru discriminare. Soluția este eficientă pe termen scurt, dar etic și juridic este periculoasă.`},
      {label:"AI + audit de bias + verificare umană + jurnalizare decizii", score:+3, tone:"good",
       fb:`Aceasta este o abordare echilibrată. AI-ul ajută la eficiență, dar deciziile finale sunt monitorizate de oameni. Auditul de bias identifică și corectează inechitățile, iar verificarea umană adaugă un strat de responsabilitate și transparență. Această combinație sprijină atât inovația, cât și principiile de etică și legalitate. Universitatea își protejează reputația și oferă candidaților un proces de admitere mai corect.`},
      {label:"Renunți complet la AI", score:+1, tone:"warn",
       fb:`Această decizie elimină riscurile de discriminare algoritmică, dar păstrează problemele actuale: comisiile de admitere pot avea și ele biasuri subiective și sunt limitate ca timp și resurse. Universitatea pierde oportunitatea de a gestiona mai eficient volumul de aplicații. Deși etic este o opțiune sigură, pe termen lung poate crea frustrări interne și întârzieri.`}
    ]
  },
  {
    title: "Recrutare: transparență și contestare",
    text: `Compania ta a început să folosească un sistem AI pentru pre-screening-ul CV-urilor, cu scopul de a accelera procesul de recrutare și a reduce încărcarea departamentului de HR. 
    Algoritmul analizează educația, experiența și cuvintele cheie din CV-uri, după care selectează automat candidații considerați potriviți. Totuși, unii candidați respinși cer claritate: 
    pe ce criterii exacte a decis AI-ulși dacă există o cale prin care pot contesta decizia?
    Presiunea publică și riscul legal cresc. Compania trebuie să decidă cât de multă transparență și posibilitate de contestare să ofere.`,
    choices: [
      {label:"Nu dezvălui nimic – „model proprietar”", score:-2, tone:"bad",
       fb:`Această decizie păstrează confidențialitatea algoritmului, dar subminează încrederea candidaților și poate încălca obligațiile de informare. 
       Oamenii percep procesul ca arbitrar și lipsit de responsabilitate, ceea ce poate genera litigii sau plângeri la autoritățile de muncă. 
       Soluția poate părea convenabilă pe termen scurt, dar compromite reputația companiei și șansele de a atrage talente.`},
      {label:"Explici logica pe scurt + canal de contestare + măsuri anti-bias", score:+3, tone:"good",
       fb:`Aceasta este o abordare echilibrată. Oferi un nivel rezonabil de transparență (explici pe scurt ce factori sunt luați în calcul), creezi un mecanism de contestare prin care un candidat poate cere revizuirea deciziei și introduci audituri periodice pentru bias. În acest fel, îmbini eficiența AI cu responsabilitatea și corectitudinea, fără să expui proprietatea intelectuală a modelului. 
       Încrederea candidaților crește și compania își protejează reputația și conformitatea legală.`},
      {label:"Publici integral codul și seturile de date", score:+1, tone:"warn",
       fb:`Această opțiune aduce transparență maximă, dar este greu de implementat și riscantă. Expunerea codului și a datelor de antrenament poate compromite drepturile de proprietate intelectuală și poate dezvălui informații sensibile sau confidențiale. Deși promovează deschiderea, soluția nu este realistă pentru majoritatea companiilor. 
       Un compromis mai bun este publicarea unui rezumat de transparență (criterii generale, măsuri anti-bias, existența auditului) și menținerea unui mecanism clar de contestare`}
    ]
  },
  {
    title: "Sănătate: date sensibile",
    text: `Un spital universitar vrea să dezvolte un model AI care să prezică posibile complicații post-operatorii, cu scopul de a salva vieți și de a reduce costurile tratamentelor. Cercetătorii consideră că performanța modelului va fi cu atât mai mare cu cât vor avea acces la date medicale mai detaliate: istoricul complet al pacienților, rezultate de laborator, imagistică medicală și chiar note clinice scrise de medici. Problema este că aceste date sunt extrem de sensibile și chiar dacă sunt eliminate numele și adresele, există riscul de re-identificare prin combinații unice de factori (vârstă, boli rare, localizare). În plus, pacienții nu au fost informați inițial că datele lor vor fi folosite pentru antrenarea unui algoritm.`,
    choices: [
      {label:"Folosim date reale neredactate pentru acuratețe", score:-3, tone:"bad",
       fb:`Această decizie poate crește performanța modelului, dar încalcă principii fundamentale de confidențialitate și legalitate (ex. GDPR și legislația privind datele medicale). Datele medicale brute expun pacienții la riscuri majore în caz de scurgere sau acces abuziv. O astfel de alegere poate duce la pierderea încrederii publicului în spital, amenzi substanțiale și procese legale. Din punct de vedere etic și juridic, este o opțiune de evitat.`},
      {label:"Anonimizare + consimțământ informat + acces limitat + DPIA", score:+3, tone:"good",
       fb:`Aceasta este abordarea recomandată și responsabilă. Prin anonimizare, reduci riscul de re-identificare; prin consimțământ informat, respecți autonomia pacienților; prin acces limitat doar la personal autorizat, protejezi datele; iar printr-un DPIA (Data Protection Impact Assessment) identifici din timp riscurile și măsurile de atenuare. Rezultatul este un echilibru între utilitatea clinică și protecția datelor, cu respectarea cadrului legal. Astfel, spitalul își menține încrederea și conformitatea.`},
      {label:"Date sintetice + validare clinică + audit", score:+2, tone:"good",
       fb:`Datele sintetice sunt o soluție promițătoare pentru a reduce riscul de re-identificare, deoarece nu aparțin unor persoane reale. Totuși, modelele bazate exclusiv pe date sintetice pot suferi de lipsă de realism și pot genera predicții mai puțin precise. De aceea, este crucială validarea clinică riguroasă pe seturi reale (cu protecții suplimentare) și realizarea de audituri periodice. Aceasta este o opțiune etică și inovatoare, dar necesită investiții și proceduri stricte pentru a fi credibilă.`}
    ]
  },
  {
    title: "Deepfake în campanie",
    text: `Lucrezi într-o agenție de comunicare politică, iar un client îți cere să creezi un video deepfake în care oponentul său politic face o declarație falsă, dar foarte credibilă. Obiectivul este ca materialul să devină viral pe rețele sociale, influențând electoratul înainte de alegeri. Clientul justifică cererea spunând că „toți ceilalți fac asta” și că este doar o strategie de marketing creativ. Tu știi însă că deepfake-urile pot fi dificil de detectat și pot afecta grav integritatea democratică și încrederea publicului în informații veridice.`,
    choices: [
      {label:"Accepți – e doar „marketing creativ”", score:-3, tone:"bad",
       fb:`Această alegere te transformă într-un participant activ la dezinformare intenționată. Video-ul poate manipula votanții, afectând direct rezultatele alegerilor și subminând democrația. Pe termen scurt, poate părea un avantaj pentru client, dar consecințele sociale, juridice și etice sunt extrem de grave. Agenția riscă scandal public, pierderea reputației și chiar răspundere legală pentru răspândirea de falsuri`},
      {label:"Refuzi și propui conținut autentic verificabil", score:+3, tone:"good",
       fb:`Aceasta este alegerea etică și sustenabilă. Refuzând să creezi deepfake-ul și oferind în schimb soluții alternative — clipuri autentice, mesaje bazate pe fapte verificabile, interviuri sau campanii creative transparente — protejezi integritatea informațională și contribui la menținerea unui spațiu public sănătos. Alegerea sprijină coeziunea socială și construiește încredere pe termen lung atât pentru client, cât și pentru agenția ta`},
      {label:"Generezi video dar aplici etichetă clară „synthetic”", score:-1, tone:"warn",
       fb:`Această opțiune pare un compromis: creezi conținutul cerut, dar îl marchezi explicit ca fiind artificial. Totuși, riscul rămâne ridicat: etichetele pot fi șterse, materialul poate fi reeditat sau redistribuit fără context, iar publicul poate fi indus în eroare oricum. Deși responsabilitatea este parțial atenuată, impactul negativ asupra opiniei publice și asupra încrederii în informație rămâne semnificativ.`}
    ]
  },
  {
    title: "Monitorizare la locul de muncă",
    text: `Managerul companiei propune implementarea unui sistem AI care să monitorizeze în detaliu activitatea angajaților: tastările, capturile de ecran și timpul petrecut pe fiecare aplicație. Argumentul principal este creșterea productivității și detectarea angajaților care „pierdeau vremea” în timpul programului. Deși tehnologia ar putea oferi date utile despre eficiență, există riscul ca supravegherea excesivă să ducă la pierderi de încredere, stres și chiar conflicte cu legislația privind protecția datelor. Compania trebuie să decidă între eficiență maximă și respectarea vieții private a angajaților`,
    choices: [
      {label:"Activezi monitorizarea completă fără informare", score:-3, tone:"bad",
       fb:`Această decizie maximizează controlul, dar are consecințe negative severe. Angajații vor percepe sistemul ca pe o invazie a vieții private, ceea ce duce la scăderea motivației și la o atmosferă tensionată. În plus, colectarea masivă și netransparentă de date contravine principiilor de minimizare a datelor și poate încălca legislația muncii și protecția datelor (ex. GDPR). Pe termen lung, compania riscă pierderea angajaților valoroși și sancțiuni legale.`},
      {label:"Consultare + scop limitat + minimizare date + opțiuni de control", score:+3, tone:"good",
       fb:`Aceasta este o abordare proporțională și echilibrată. Înainte de implementare, compania organizează o consultare cu angajații și explică scopul precis al monitorizării (de exemplu, optimizarea fluxurilor de lucru, nu urmărirea personală). Se colectează doar date strict necesare, accesul la acestea este limitat, iar angajații au opțiuni de control și transparență (ex. pot vedea ce date sunt înregistrate). Această decizie reduce riscurile, menține încrederea și respectă atât eficiența, cât și drepturile fundamentale.`},
      {label:"Renunți la orice monitorizare", score:+1, tone:"warn",
       fb:`Această alegere protejează în totalitate confidențialitatea și autonomia angajaților, eliminând orice risc de abuz. Totuși, compania pierde oportunitatea de a obține date utile pentru îmbunătățirea proceselor și a productivității. O soluție de compromis ar fi să folosești instrumente moderate și transparente, axate pe indicatori de performanță colectivi și nu pe supravegherea intruzivă individuală. În acest fel, se menține echilibrul între performanță și respectarea vieții private.`}
    ]
  },
  {
    title: "Student și utilizarea AI la lucrări",
    text: `Ești student(ă) și te apropii de sesiune. În fața ta stă o temă importantă, iar mai târziu te așteaptă și
  redactarea lucrării de licență. Tentația este să folosești un model AI generativ pentru a scrie rapid eseul,
  pentru a genera schițe de capitole sau chiar pentru a formula concluziile. Profesorii însă au avertizat că
  folosirea neetică a AI-ului poate fi considerată plagiat, dar nu au stabilit reguli foarte clare. Cum procedezi?`,
    choices: [
      {label:"Predai textul generat de AI fără modificări", score:-2, tone:"bad",
       fb:`Această alegere îți aduce un câștig rapid de timp, dar riști consecințe grave: textul poate conține
      halucinații sau erori, nu reflectă munca ta reală și poate fi considerat plagiat. În plus, lipsa de
      înțelegere a conținutului te va afecta la examene sau susținerea lucrării.`},
      {label:"Folosești AI ca suport (structură, idei) + verifici și rescrii cu propriile cuvinte", score:+3, tone:"good",
       fb:`Aceasta este o abordare responsabilă. AI-ul te ajută să economisești timp și să obții inspirație, dar
      tu rămâi autorul principal: verifici sursele, rescrii, adaugi exemple proprii și menționezi transparent
      utilizarea instrumentului. Astfel, înveți efectiv și eviți problemele de etică și integritate academică.`},
      {label:"Eviți complet AI pentru teme și lucrări", score:+1, tone:"warn",
       fb:`Această alegere elimină orice risc de plagiat și te obligă să muncești independent, dar pierzi și
      beneficiile legitime pe care AI-ul ți le-ar putea aduce (organizare, sugestii, idei). Pe termen lung,
      cu reguli clare și transparență, folosirea moderată a AI-ului poate fi o resursă utilă.`}
    ]
  },
  {
    title: "Educație: detecție plagiat AI",
    text: `La o universitate, profesorii se confruntă cu o problemă nouă: studenții folosesc instrumente de inteligență artificială generativă pentru a scrie eseuri, proiecte și chiar lucrări de cercetare. Pentru a menține standardele academice, conducerea propune folosirea unui detector AI obligatoriu pentru toate temele. Conform propunerii, fiecare lucrare ar fi scanată automat, iar dacă detectorul o clasifică drept „scrisă cu AI”, studentul ar fi penalizat imediat, fără o verificare suplimentară. Profesorii sunt împărțiți: unii consideră că aceasta este singura soluție pentru a combate trișatul, alții atrag atenția asupra riscului de erori de clasificare și asupra impactului negativ asupra procesului educațional. Universitatea trebuie să decidă cum va folosi aceste instrumente, astfel încât să echilibreze integritatea academică cu drepturile și învățarea autentică a studenților.`,
    choices: [
      {label:"Obligi detectorul și penalizezi automat", score:-2, tone:"bad",
       fb:`Această decizie transmite un mesaj de fermitate, dar are consecințe problematice. Detectoarele AI nu sunt infailibile și pot genera fals pozitive, adică să marcheze lucrări originale ca fiind produse de AI. Penalizarea automată fără o verificare umană duce la lipsa de due process (dreptul studentului de a-și apăra munca). În plus, măsura poate crea o atmosferă de neîncredere și frică, descurajând creativitatea și procesul de învățare autentic.`},
      {label:"Detector + discuție cu studentul + redesign evaluări + politică clară", score:+3, tone:"good",
       fb:`Aceasta este abordarea responsabilă și pedagogică. Detectorul este folosit doar ca instrument de sprijin, nu ca judecător absolut. Dacă o lucrare ridică semne de întrebare, profesorul discută cu studentul pentru a înțelege procesul de lucru. În paralel, universitatea redeseniază evaluările (de ex. teme mai aplicate, prezentări orale, examene interactive) și introduce o politică clară privind utilizarea AI. Astfel, se încurajează onestitatea academică și se dezvoltă abilități reale, fără a penaliza nedrept.`},
      {label:"Nu folosești deloc detectorul", score:+1, tone:"warn",
       fb:`Această alegere elimină riscul de erori de clasificare, dar face mai dificilă identificarea cazurilor reale de abuz. Profesorii trebuie să se bazeze doar pe intuiție sau metode tradiționale, ceea ce poate fi ineficient. Totuși, dacă este însoțită de alte metode de evaluare inovative (proiecte colaborative, examene supravegheate, interviuri de verificare), lipsa detectorului poate fi compensată. Este o opțiune etică și sigură, dar necesită soluții alternative bine gândite.`}
    ]
  },
  {
    title: "Campus: recunoaștere facială la intrare",
    text: `Administrația universității propune instalarea unor camere cu recunoaștere facială la intrările în clădiri, pentru a accelera accesul studenților și pentru a crește siguranța campusului. Argumentele sunt că această tehnologie ar putea preveni intrările neautorizate, ar simplifica fluxul la ore de vârf și ar permite reacții rapide în caz de incidente. Totuși, apar mai multe îngrijorări: datele biometrice sunt extrem de sensibile și unică expunere poate compromite identitatea unei persoane pentru tot restul vieții; există riscul de profilare și discriminare, deoarece algoritmii de recunoaștere facială funcționează mai puțin precis pe anumite grupuri etnice și de gen; studenții și profesorii se tem că se va crea un climat de supraveghere permanentă, incompatibil cu libertatea academică.
Administrația trebuie să decidă cum procedează`,
    choices: [
      {label:"Activezi imediat – securitatea înainte de toate", score:-3, tone:"bad",
       fb:`Această alegere maximizează rapid siguranța, dar sacrifică drepturile fundamentale. Instalezi un sistem de supraveghere intruzivă fără analiză de risc sau consultare. Erorile de recunoaștere pot duce la discriminare (de exemplu, acces refuzat disproporționat anumitor grupuri), iar colectarea masivă de date biometrice expune universitatea la riscuri legale și reputaționale. Pe termen lung, creezi un climat de frică și neîncredere, subminând chiar scopul educațional al campusului.`},
      {label:"Analiză de risc + pilot limitat + alternativă non-biometrică + ștergere rapidă", score:+3, tone:"good",
       fb:`Aceasta este o soluție echilibrată. Înainte de implementare faci o analiză de impact (DPIA), lansezi un proiect-pilot într-o singură clădire, oferi opțiuni alternative (badge-uri, coduri PIN) pentru cei care nu doresc să își ofere date biometrice și aplici reguli stricte de stocare temporară și ștergere rapidă a datelor. Astfel, obții unele beneficii ale tehnologiei, dar limitezi riscurile și păstrezi încrederea comunității universitare.`},
      {label:"Refuzi orice folosire de biometrie", score:+2, tone:"good",
       fb:`Această decizie elimină complet riscurile asociate recunoașterii faciale și transmite un mesaj puternic de respect pentru drepturile și libertățile individuale. Totuși, universitatea trebuie să ofere alternative sigure și eficiente pentru controlul accesului (badge-uri inteligente, coduri PIN, carduri magnetice). În plus, este important ca refuzul să fie documentat și justificat prin politici clare, pentru a arăta că decizia nu este doar de moment, ci parte a unei strategii coerente de securitate.`}
    ]
  }
];

function personaFromScore(score){
  // 8 scenarii, max 24 puncte
  if(score >= 17) return {key:"guardian", name:"🛡️ Guardian", desc:"Prioritizezi drepturile, transparența și controlul uman. Ești consecvent(ă) în aplicarea principiilor și alegi măsuri proporționale cu risc scăzut."};
  if(score >= 12) return {key:"balancer", name:"⚖️ Balancer", desc:"Cauți echilibrul între inovație și risc. Folosești AI cu protecții solide (audit, explicabilitate, guvernanță), dar rămâi deschis(ă) la îmbunătățiri."};
  if(score >= 6)  return {key:"innovator", name:"🚀 Innovator", desc:"Valorezi inovația și viteza; uneori minimizezi riscurile. Cu reguli și verificări mai riguroase, poți atinge rapid un standard înalt."};
  return {key:"risk", name:"🎭 Risk-Taker", desc:"Asumi riscuri mari și ignori adesea consecințele. Recalibrează pe confidențialitate, bias, transparență și protecția utilizatorilor."};
}

let step = 0, score = 0;
const gameEl = document.getElementById("game");
const endEl  = document.getElementById("end");
const progEl = document.getElementById("prog");
const stepTxt = document.getElementById("stepTxt");
const scoreTxt = document.getElementById("scoreTxt");

function renderStep(){
  const s = scenarios[step];
  progEl.style.width = Math.round((step/scenarios.length)*100) + "%";
  stepTxt.textContent = `Scenariul ${step+1}/${scenarios.length}`;
  scoreTxt.textContent = score;

  gameEl.innerHTML = `
    <h2>${s.title}</h2>
    <div>${s.text}</div>
    <div class="choices"></div>
    <div class="small" style="opacity:.85;margin-top:6px">
      Alege o variantă; primești feedback imediat. Apasă „Următorul scenariu” când ești gata să continui.
    </div>
  `;
  const choicesEl = gameEl.querySelector(".choices");
  s.choices.forEach(c=>{
    const btn = document.createElement("div");
    btn.className = "choice";
    btn.textContent = c.label;
    btn.onclick = ()=>{
      score += c.score; scoreTxt.textContent = score;
      btn.classList.add(c.tone);
      // dezactivează celelalte opțiuni
      [...choicesEl.children].forEach(ch=>ch.style.pointerEvents="none");
      // feedback persistent + buton Next
      const fb=document.createElement("div");
      fb.className="feedback "+c.tone;
      fb.innerHTML = `<div style="line-height:1.45">${c.fb}</div>`;
      const nextBtn = document.createElement("button");
      nextBtn.textContent = "Următorul scenariu ▶";
      nextBtn.style.marginTop = "12px";
      nextBtn.onclick = nextStep;
      fb.appendChild(nextBtn);
      choicesEl.after(fb);
    };
    choicesEl.appendChild(btn);
  });
}

function nextStep(){
  step++;
  if(step<scenarios.length) renderStep(); else finish();
}

function finish(){
  progEl.style.width="100%";
  gameEl.style.display="none";
  const p=personaFromScore(score);
  endEl.style.display="block";

  const recs = {
    guardian: [
      "Documentează practicile (registre decizionale, DPIA, politici).",
      "Împarte template-uri și checklisturi cu echipa.",
      "Verifică periodic proporționalitatea (evită „over-compliance”)."
    ],
    balancer: [
      "Formalizează guvernanța: roluri, audit regulat, plan de incidente.",
      "Canale clare pentru contestări și feedback al utilizatorilor.",
      "Experimentează în sandbox-uri cu măsurare de risc/impact."
    ],
    innovator: [
      "Adaugă evaluări sistematice de bias și revizuire umană.",
      "Publică un rezumat de transparență (date, scop, protecții).",
      "Definește praguri de risc care blochează lansarea până la remedieri."
    ],
    risk: [
      "Folosește un checklist minimal (consimțământ, minimizare, audit de bias, logging).",
      "Implică un ‘ethics buddy’/comitet la decizii cheie.",
      "Începe cu proiecte pilot mici; măsoară efectele și corectează rapid."
    ]
  };

  const why = [
    "Preferință pentru audit, consimțământ, transparență și control uman.",
    "Soluții proporționale, nu extreme.",
    "Evitarea dezinformării și a supravegherii intruzive.",
    "Protecția confidențialității și minimizarea datelor."
  ];

  endEl.innerHTML = `
    <div class="persona">
      <div class="badge">${p.name.split(" ")[0]}</div>
      <div>
        <h2 style="margin:0">${p.name}</h2>
        <div class="small">${p.desc}</div>
      </div>
    </div>
    <div class="two" style="margin-top:14px">
      <div class="card" style="background:#0e1428">
        <div class="small">Scor final</div>
        <h3 style="margin:.2rem 0">${score} / ${scenarios.length*3}</h3>
        <div class="small">(${scenarios.length} scenarii, +3 = etic, +2 = foarte bun, +1 = sigur dar limitativ, negative = problematice)</div>
      </div>
      <div class="card" style="background:#0e1428">
        <div class="small">De ce ai obținut acest profil</div>
        <ul>${why.map(x=>`<li>${x}</li>`).join("")}</ul>
      </div>
    </div>
    <div class="card tip">
      <div class="small"><b>Pașii următori recomandați pentru profilul tău</b></div>
      <ul>${recs[p.key].map(x=>`<li>${x}</li>`).join("")}</ul>
    </div>
    <div class="footer">
      <button id="restart">Repornește</button>
      <button class="secondary" onclick="location.href='index.html'">Înapoi la Quiz</button>
    </div>
  `;
  document.getElementById("restart").onclick = () => location.reload();
}

renderStep();
</script>
</body>
</html>
